{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da21ed99",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/historical-station-counts-2023.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m     14\u001b[0m historical_data_2014 \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData/historical-station-counts-2014.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# ----------------------------------------------\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#2023 Data building\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Read Data File and store into Pandas DataFrames \u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m historical_data2023\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(historical_data_2023)\n\u001b[1;32m     20\u001b[0m historical_data2023\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m historical_data2023\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     21\u001b[0m historical_data2023 \u001b[38;5;241m=\u001b[39m historical_data2023\u001b[38;5;241m.\u001b[39mdrop(historical_data2023\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m3\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/historical-station-counts-2023.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "# File to Load\n",
    "\n",
    "historical_data_2023 = Path(\"Data_For_PostgresData/historical-station-counts-2023.csv\")\n",
    "historical_data_2022 = Path(\"Data/historical-station-counts-2022.csv\")\n",
    "historical_data_2021 = Path(\"Data/historical-station-counts-2021.csv\")\n",
    "historical_data_2020 = Path(\"Data/historical-station-counts-2020.csv\")\n",
    "historical_data_2019 = Path(\"Data/historical-station-counts-2019.csv\")\n",
    "historical_data_2018 = Path(\"Data/historical-station-counts-2018.csv\")\n",
    "historical_data_2017 = Path(\"Data/historical-station-counts-2017.csv\")\n",
    "historical_data_2016 = Path(\"Data/historical-station-counts-2016.csv\")\n",
    "historical_data_2015 = Path(\"Data/historical-station-counts-2015.csv\")\n",
    "historical_data_2014 = Path(\"Data/historical-station-counts-2014.csv\")\n",
    "\n",
    "# ----------------------------------------------\n",
    "#2023 Data building\n",
    "# Read Data File and store into Pandas DataFrames \n",
    "historical_data2023= pd.read_csv(historical_data_2023)\n",
    "historical_data2023.columns = historical_data2023.iloc[0]\n",
    "historical_data2023 = historical_data2023.drop(historical_data2023.index[0:3])\n",
    "# Show DataFrame\n",
    "historical_data2023.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eb9df3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'historical_data2023' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Make it pretty\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m historical_data2023 \u001b[38;5;241m=\u001b[39m historical_data2023\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mElectrica\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mElectric\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHydrogenb\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHydrogen\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPropanec\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPropane\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotald\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Drop end rows, set index by state drop ,everyother row for extra station level data\u001b[39;00m\n\u001b[1;32m      5\u001b[0m historical_data_clean2023 \u001b[38;5;241m=\u001b[39m historical_data2023\u001b[38;5;241m.\u001b[39mdrop(historical_data2023\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m103\u001b[39m:\u001b[38;5;241m110\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'historical_data2023' is not defined"
     ]
    }
   ],
   "source": [
    "# Make it pretty\n",
    "historical_data2023 = historical_data2023.rename(columns={\"Electrica\":\"Electric\", \"Hydrogenb\":\"Hydrogen\", \"Propanec\":\"Propane\",\"Totald\":\"Total\"})\n",
    "\n",
    "# Drop end rows, set index by state drop ,everyother row for extra station level data\n",
    "historical_data_clean2023 = historical_data2023.drop(historical_data2023.index[103:110])\n",
    "historical_data_clean2023 = historical_data_clean2023.set_index([\"State\"])\n",
    "historical_data_clean2023= historical_data_clean2023.iloc[::2]\n",
    "\n",
    "#print dataframe\n",
    "historical_data_clean2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa17c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the \"Electric\" column and check the resulting columns\n",
    "split_columns2023 = historical_data_clean2023[\"Electric\"].str.split(' | ', expand=True)\n",
    "print(split_columns2023.head())  # Check the number of columns created\n",
    "\n",
    "# If the split operation creates more than 3 columns, adjust the assignment accordingly\n",
    "if split_columns2023.shape[1] >= 3:\n",
    "    historical_data_clean2023[[\"Electric Stations\",\"unneeded\", \"Electric Charging Outlets\"]] = split_columns2023.iloc[:, :3]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns to assign to 'Electrical Stations' and 'Electrical Charging Outlets'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5591535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the \"Hydrogen\" column and check the resulting columns\n",
    "split_columns_hy2023 = historical_data_clean2023[\"Hydrogen\"].str.split(' | | ', expand=True)\n",
    "print(split_columns_hy2023.head())  # Check the number of columns created\n",
    "\n",
    "# If the split operation creates more than 5 columns, adjust the assignment accordingly\n",
    "if split_columns_hy2023.shape[1] >= 5:\n",
    "    historical_data_clean2023[[\"Hydrogen Retail\",\"unneeded2\",\"Hydrogen Non-Retail\",\"unneeded3\", \"Hydrogen Total\"]] = split_columns_hy2023.iloc[:, :5]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77986702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the \"Propane\" column and check the resulting columns\n",
    "split_columns_pr2023 = historical_data_clean2023[\"Propane\"].str.split(' | | ', expand=True)\n",
    "print(split_columns_pr2023.head())  # Check the number of columns created\n",
    "\n",
    "# If the split operation creates more than 5 columns, adjust the assignment accordingly\n",
    "if split_columns_pr2023.shape[1] >= 5:\n",
    "    historical_data_clean2023[[\"Propane Primary\",\"unneeded4\",\"Propane Secondary\",\"unneeded5\", \"Propane Total\"]] = split_columns_pr2023.iloc[:, :5]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afda86ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(historical_data_clean2023.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dd719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unneeded column\n",
    "historical2023 = historical_data_clean2023.drop(columns=[\"Electric\",\"Hydrogen\",\"Propane\",\"unneeded\",\"unneeded2\",\"unneeded3\",\"unneeded4\",\"unneeded5\"])\n",
    "historical2023.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa5d2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to float\n",
    "historical2023 = historical2023.applymap(lambda x: x.replace(',', '') if isinstance(x, str) else x)\n",
    "historical2023 = historical2023.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19199569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dtypes\n",
    "historical2023.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cc23d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Electric Total column \n",
    "# Put columns in correct order\n",
    "historical2023['Electric Total']= historical2023[['Electric Stations','Electric Charging Outlets']].sum(axis=1)\n",
    "historical2023['Year']='2023'\n",
    "historical_df_2023 = historical2023.reindex(columns=['Year','Biodiesel','CNG','E85','Electric Stations','Electric Charging Outlets',\n",
    "                                           'Electric Total','Hydrogen Retail','Hydrogen Non-Retail','Hydrogen Total',\n",
    "                                           'LNG','Propane Primary','Propane Secondary', 'Propane Total','Total'])\n",
    "historical_df_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8ab325",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_df_2023.to_csv('historical_df_2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af38a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "#2022 data building \n",
    "# Read Data File and store into Pandas DataFrames \n",
    "historical_data2022= pd.read_csv(historical_data_2022)\n",
    "historical_data2022.columns = historical_data2022.iloc[0]\n",
    "historical_data2022 = historical_data2022.drop(historical_data2022.index[0:3])\n",
    "# Show DataFrame\n",
    "historical_data2022.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae29e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e03f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make it pretty\n",
    "historical_data2022 = historical_data2022.rename(columns={\"Electrica\":\"Electric\", \"Hydrogenb\":\"Hydrogen\", \"Propanec\":\"Propane\",\"Totald\":\"Total\"})\n",
    "\n",
    "# Drop end rows, set index by state drop ,everyother row for extra station level data\n",
    "historical_data_clean2022 = historical_data2022.drop(historical_data2022.index[103:110])\n",
    "historical_data_clean2022 = historical_data_clean2022.set_index([\"State\"])\n",
    "historical_data_clean2022= historical_data_clean2022.iloc[::2]\n",
    "\n",
    "#print dataframe\n",
    "historical_data_clean2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66f522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the \"Electric\" column and check the resulting columns\n",
    "split_columns2022 = historical_data_clean2022[\"Electric\"].str.split(' | ', expand=True)\n",
    "print(split_columns2022.head())  # Check the number of columns created\n",
    "\n",
    "# If the split operation creates more than 3 columns, adjust the assignment accordingly\n",
    "if split_columns2022.shape[1] >= 3:\n",
    "    historical_data_clean2022[[\"Electric Stations\",\"unneeded\", \"Electric Charging Outlets\"]] = split_columns2022.iloc[:, :3]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns to assign to 'Electrical Stations' and 'Electrical Charging Outlets'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fab36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the \"Hydrogen\" column and check the resulting columns\n",
    "split_columns_hy2022 = historical_data_clean2022[\"Hydrogen\"].str.split(' | | ', expand=True)\n",
    "print(split_columns_hy2022.head())  # Check the number of columns created\n",
    "\n",
    "# If the split operation creates more than 5 columns, adjust the assignment accordingly\n",
    "if split_columns_hy2022.shape[1] >= 5:\n",
    "    historical_data_clean2022[[\"Hydrogen Retail\",\"unneeded2\",\"Hydrogen Non-Retail\",\"unneeded3\", \"Hydrogen Total\"]] = split_columns_hy2022.iloc[:, :5]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b23153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the \"Propane\" column and check the resulting columns\n",
    "split_columns_pr2022 = historical_data_clean2022[\"Propane\"].str.split(' | | ', expand=True)\n",
    "print(split_columns_pr2022.head())  # Check the number of columns created\n",
    "\n",
    "# If the split operation creates more than 5 columns, adjust the assignment accordingly\n",
    "if split_columns_pr2022.shape[1] >= 5:\n",
    "    historical_data_clean2022[[\"Propane Primary\",\"unneeded4\",\"Propane Secondary\",\"unneeded5\", \"Propane Total\"]] = split_columns_pr2022.iloc[:, :5]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad32995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(historical_data_clean2022.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1433c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unneeded column\n",
    "historical2022 = historical_data_clean2022.drop(columns=[\"Electric\",\"Hydrogen\",\"Propane\",\"unneeded\",\"unneeded2\",\"unneeded3\",\"unneeded4\",\"unneeded5\"])\n",
    "historical2022.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c8a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to float\n",
    "historical2022 = historical2022.applymap(lambda x: x.replace(',', '') if isinstance(x, str) else x)\n",
    "historical2022 = historical2022.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58322d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dtypes\n",
    "historical2022.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef03f64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Electric Total column \n",
    "# Put columns in correct order\n",
    "historical2022['Electric Total']= historical2022[['Electric Stations','Electric Charging Outlets']].sum(axis=1)\n",
    "historical2022['Year']='2022'\n",
    "historical_df_2022 = historical2022.reindex(columns=['Year','Biodiesel','CNG','E85','Electric Stations','Electric Charging Outlets',\n",
    "                                           'Electric Total','Hydrogen Retail','Hydrogen Non-Retail','Hydrogen Total',\n",
    "                                           'LNG','Propane Primary','Propane Secondary', 'Propane Total','Total'])\n",
    "historical_df_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06076d20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "historical_df_2022.to_csv('historical_df_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fefbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------\n",
    "#2021 data building \n",
    "historical_data2021= pd.read_csv(historical_data_2021)\n",
    "historical_data2021.columns = historical_data2021.iloc[0]\n",
    "historical_data2021 = historical_data2021.drop(historical_data2021.index[0:3])\n",
    "# Show DataFrame\n",
    "historical_data2021.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6263a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make it pretty\n",
    "historical_data2021 = historical_data2021.rename(columns={\"Electrica\":\"Electric\", \"Hydrogenb\":\"Hydrogen\", \"Propanec\":\"Propane\",\"Totald\":\"Total\"})\n",
    "\n",
    "# Drop end rows, set index by state drop ,everyother row for extra station level data\n",
    "historical_data_clean2021 = historical_data2021.drop(historical_data2021.index[103:110])\n",
    "historical_data_clean2021 = historical_data_clean2021.set_index([\"State\"])\n",
    "historical_data_clean2021= historical_data_clean2021.iloc[::2]\n",
    "\n",
    "#print dataframe\n",
    "historical_data_clean2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07de37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the \"Electric\" column and check the resulting columns\n",
    "split_columns2021 = historical_data_clean2021[\"Electric\"].str.split(' | ', expand=True)\n",
    "print(split_columns2021.head())  # Check the number of columns created\n",
    "\n",
    "# If the split operation creates more than 3 columns, adjust the assignment accordingly\n",
    "if split_columns2021.shape[1] >= 3:\n",
    "    historical_data_clean2021[[\"Electric Stations\",\"unneeded\", \"Electric Charging Outlets\"]] = split_columns2021.iloc[:, :3]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns to assign to 'Electrical Stations' and 'Electrical Charging Outlets'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ff624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the \"Hydrogen\" column and check the resulting columns\n",
    "split_columns_hy2021 = historical_data_clean2021[\"Hydrogen\"].str.split(' | | ', expand=True)\n",
    "print(split_columns_hy2021.head())  # Check the number of columns created\n",
    "\n",
    "# If the split operation creates more than 5 columns, adjust the assignment accordingly\n",
    "if split_columns_hy2021.shape[1] >= 5:\n",
    "    historical_data_clean2021[[\"Hydrogen Retail\",\"unneeded2\",\"Hydrogen Non-Retail\",\"unneeded3\", \"Hydrogen Total\"]] = split_columns_hy2021.iloc[:, :5]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f1ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the \"Propane\" column and check the resulting columns\n",
    "split_columns_pr2021 = historical_data_clean2021[\"Propane\"].str.split(' | | ', expand=True)\n",
    "print(split_columns_pr2021.head())  # Check the number of columns created\n",
    "\n",
    "# If the split operation creates more than 5 columns, adjust the assignment accordingly\n",
    "if split_columns_pr2021.shape[1] >= 5:\n",
    "    historical_data_clean2021[[\"Propane Primary\",\"unneeded4\",\"Propane Secondary\",\"unneeded5\", \"Propane Total\"]] = split_columns_pr2021.iloc[:, :5]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad24f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(historical_data_clean2021.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31338cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unneeded column\n",
    "historical2021 = historical_data_clean2021.drop(columns=[\"Electric\",\"Hydrogen\",\"Propane\",\"unneeded\",\"unneeded2\",\"unneeded3\",\"unneeded4\",\"unneeded5\"])\n",
    "historical2021.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b6de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to float\n",
    "historical2021 = historical2021.applymap(lambda x: x.replace(',', '') if isinstance(x, str) else x)\n",
    "historical2021 = historical2021.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2688fa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dtypes\n",
    "historical2021.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d246ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Electric Total column \n",
    "# Put columns in correct order\n",
    "historical2021['Electric Total']= historical2021[['Electric Stations','Electric Charging Outlets']].sum(axis=1)\n",
    "historical2021['Year']='2021'\n",
    "historical_df_2021 = historical2021.reindex(columns=['Year','Biodiesel','CNG','E85','Electric Stations','Electric Charging Outlets',\n",
    "                                           'Electric Total','Hydrogen Retail','Hydrogen Non-Retail','Hydrogen Total',\n",
    "                                           'LNG','Propane Primary','Propane Secondary', 'Propane Total','Total'])\n",
    "historical_df_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d459d77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_df_2021.to_csv('historical_df_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4445e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------\n",
    "# data building 2020\n",
    "historical_data2020= pd.read_csv(historical_data_2020)\n",
    "historical_data2020.columns = historical_data2020.iloc[0]\n",
    "historical_data2020 = historical_data2020.drop(historical_data2020.index[0:3])\n",
    "# Show DataFrame\n",
    "historical_data2020.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afa52cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make it pretty\n",
    "historical_data2020 = historical_data2020.rename(columns={\"Electrica\":\"Electric\", \"Hydrogenb\":\"Hydrogen\", \"Propanec\":\"Propane\",\"Totald\":\"Total\"})\n",
    "\n",
    "# Drop end rows, set index by state drop ,everyother row for extra station level data\n",
    "historical_data_clean2020 = historical_data2020.drop(historical_data2020.index[103:110])\n",
    "historical_data_clean2020 = historical_data_clean2020.set_index([\"State\"])\n",
    "historical_data_clean2020= historical_data_clean2020.iloc[::2]\n",
    "\n",
    "#print dataframe\n",
    "historical_data_clean2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c30a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the \"Electric\" column and check the resulting columns\n",
    "split_columns2020 = historical_data_clean2020[\"Electric\"].str.split(' | ', expand=True)\n",
    "print(split_columns2020.head())  # Check the number of columns created\n",
    "\n",
    "# If the split operation creates more than 3 columns, adjust the assignment accordingly\n",
    "if split_columns2020.shape[1] >= 3:\n",
    "    historical_data_clean2020[[\"Electric Stations\",\"unneeded\", \"Electric Charging Outlets\"]] = split_columns2020.iloc[:, :3]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns to assign to 'Electrical Stations' and 'Electrical Charging Outlets'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99379270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the \"Hydrogen\" column and check the resulting columns\n",
    "split_columns_hy2020 = historical_data_clean2020[\"Hydrogen\"].str.split(' | | ', expand=True)\n",
    "print(split_columns_hy2020.head())  # Check the number of columns created\n",
    "\n",
    "# If the split operation creates more than 5 columns, adjust the assignment accordingly\n",
    "if split_columns_hy2020.shape[1] >= 5:\n",
    "    historical_data_clean2020[[\"Hydrogen Retail\",\"unneeded2\",\"Hydrogen Non-Retail\",\"unneeded3\", \"Hydrogen Total\"]] = split_columns_hy2020.iloc[:, :5]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f05b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the \"Propane\" column and check the resulting columns\n",
    "split_columns_pr2020 = historical_data_clean2020[\"Propane\"].str.split(' | | ', expand=True)\n",
    "print(split_columns_pr2020.head())  # Check the number of columns created\n",
    "\n",
    "# If the split operation creates more than 5 columns, adjust the assignment accordingly\n",
    "if split_columns_pr2020.shape[1] >= 5:\n",
    "    historical_data_clean2020[[\"Propane Primary\",\"unneeded4\",\"Propane Secondary\",\"unneeded5\", \"Propane Total\"]] = split_columns_pr2020.iloc[:, :5]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be59a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(historical_data_clean2020.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc4e619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unneeded column\n",
    "historical2020 = historical_data_clean2020.drop(columns=[\"Electric\",\"Hydrogen\",\"Propane\",\"unneeded\",\"unneeded2\",\"unneeded3\",\"unneeded4\",\"unneeded5\"])\n",
    "historical2020.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b56e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to float\n",
    "historical2020 = historical2020.applymap(lambda x: x.replace(',', '') if isinstance(x, str) else x)\n",
    "historical2020 = historical2020.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b112cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dtypes\n",
    "historical2020.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e37390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Electric Total column \n",
    "# Put columns in correct order\n",
    "historical2020['Electric Total']= historical2020[['Electric Stations','Electric Charging Outlets']].sum(axis=1)\n",
    "historical2020['Year']='2020'\n",
    "historical_df_2020 = historical2020.reindex(columns=['Year','Biodiesel','CNG','E85','Electric Stations','Electric Charging Outlets',\n",
    "                                           'Electric Total','Hydrogen Retail','Hydrogen Non-Retail','Hydrogen Total',\n",
    "                                           'LNG','Propane Primary','Propane Secondary', 'Propane Total','Total'])\n",
    "historical_df_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367b4ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_df_2020.to_csv('historical_df_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e619eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------\n",
    "# Data for 2019-2014\n",
    "# Read Data File and store into Pandas DataFrames \n",
    "# 2019\n",
    "historical_data2019= pd.read_csv(historical_data_2019)\n",
    "historical_data2019.columns = historical_data2019.iloc[0]\n",
    "historical_data2019 = historical_data2019.drop(historical_data2019.index[0:3])\n",
    "#2018\n",
    "historical_data2018= pd.read_csv(historical_data_2018)\n",
    "historical_data2018.columns = historical_data2018.iloc[0]\n",
    "historical_data2018 = historical_data2018.drop(historical_data2018.index[0:3])\n",
    "#2017\n",
    "historical_data2017= pd.read_csv(historical_data_2017)\n",
    "historical_data2017.columns = historical_data2017.iloc[0]\n",
    "historical_data2017 = historical_data2017.drop(historical_data2017.index[0:3])\n",
    "#2016\n",
    "historical_data2016= pd.read_csv(historical_data_2016)\n",
    "historical_data2016.columns = historical_data2016.iloc[0]\n",
    "historical_data2016 = historical_data2016.drop(historical_data2016.index[0:3])\n",
    "#2015\n",
    "historical_data2015= pd.read_csv(historical_data_2015)\n",
    "historical_data2015.columns = historical_data2015.iloc[0]\n",
    "historical_data2015 = historical_data2015.drop(historical_data2015.index[0:3])\n",
    "#2014\n",
    "historical_data2014= pd.read_csv(historical_data_2014)\n",
    "historical_data2014.columns = historical_data2014.iloc[0]\n",
    "historical_data2014 = historical_data2014.drop(historical_data2014.index[0:3])\n",
    "\n",
    "# Show DataFrame\n",
    "historical_data2019.head()\n",
    "#historical_data2018.head()\n",
    "#historical_data2017.head()\n",
    "#historical_data2016.head()\n",
    "#historical_data2015.head()\n",
    "#historical_data2014.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daea5694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019\n",
    "# Make it pretty\n",
    "historical_data2019 = historical_data2019.rename(columns={\"Electrica\":\"Electric\", \"Hydrogenb\":\"Hydrogen\", \"Propanec\":\"Propane\",\"Totald\":\"Total\"})\n",
    "# Drop end rows, set index by state drop ,everyother row for extra station level data\n",
    "historical_data_clean2019 = historical_data2019.drop(historical_data2019.index[103:110])\n",
    "historical_data_clean2019 = historical_data_clean2019.set_index([\"State\"])\n",
    "historical_data_clean2019= historical_data_clean2019.iloc[::2]\n",
    "# 2018\n",
    "# Make it pretty\n",
    "historical_data2018 = historical_data2018.rename(columns={\"Electrica\":\"Electric\", \"Hydrogenb\":\"Hydrogen\", \"Propanec\":\"Propane\",\"Totald\":\"Total\"})\n",
    "# Drop end rows, set index by state drop ,everyother row for extra station level data\n",
    "historical_data_clean2018 = historical_data2018.drop(historical_data2018.index[103:110])\n",
    "historical_data_clean2018 = historical_data_clean2018.set_index([\"State\"])\n",
    "historical_data_clean2018= historical_data_clean2018.iloc[::2]\n",
    "# 2017\n",
    "# Make it pretty\n",
    "historical_data2017 = historical_data2017.rename(columns={\"Electrica\":\"Electric\", \"Hydrogenb\":\"Hydrogen\", \"Propanec\":\"Propane\",\"Totald\":\"Total\"})\n",
    "# Drop end rows, set index by state drop ,everyother row for extra station level data\n",
    "historical_data_clean2017 = historical_data2017.drop(historical_data2017.index[103:110])\n",
    "historical_data_clean2017 = historical_data_clean2017.set_index([\"State\"])\n",
    "historical_data_clean2017= historical_data_clean2017.iloc[::2]\n",
    "# 2016\n",
    "# Make it pretty\n",
    "historical_data2016 = historical_data2016.rename(columns={\"Electrica\":\"Electric\", \"Hydrogenb\":\"Hydrogen\", \"Propanec\":\"Propane\",\"Totald\":\"Total\"})\n",
    "# Drop end rows, set index by state drop ,everyother row for extra station level data\n",
    "historical_data_clean2016 = historical_data2016.drop(historical_data2016.index[103:110])\n",
    "historical_data_clean2016 = historical_data_clean2016.set_index([\"State\"])\n",
    "historical_data_clean2016= historical_data_clean2016.iloc[::2]\n",
    "# 2015\n",
    "# Make it pretty\n",
    "historical_data2015 = historical_data2015.rename(columns={\"Electrica\":\"Electric\", \"Hydrogenb\":\"Hydrogen\", \"Propanec\":\"Propane\",\"Totald\":\"Total\"})\n",
    "# Drop end rows, set index by state drop ,everyother row for extra station level data\n",
    "historical_data_clean2015 = historical_data2015.drop(historical_data2015.index[103:110])\n",
    "historical_data_clean2015 = historical_data_clean2015.set_index([\"State\"])\n",
    "historical_data_clean2015= historical_data_clean2015.iloc[::2]\n",
    "# 2014\n",
    "# Make it pretty\n",
    "historical_data2014 = historical_data2014.rename(columns={\"Electrica\":\"Electric\", \"Hydrogenb\":\"Hydrogen\", \"Propanec\":\"Propane\",\"Totald\":\"Total\"})\n",
    "# Drop end rows, set index by state drop ,everyother row for extra station level data\n",
    "historical_data_clean2014 = historical_data2014.drop(historical_data2014.index[103:110])\n",
    "historical_data_clean2014 = historical_data_clean2014.set_index([\"State\"])\n",
    "historical_data_clean2014= historical_data_clean2014.iloc[::2]\n",
    "\n",
    "#print dataframe\n",
    "historical_data_clean2019\n",
    "#historical_data_clean2018\n",
    "#historical_data_clean2017\n",
    "#historical_data_clean2016\n",
    "#historical_data_clean2015\n",
    "#historical_data_clean2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394ab07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2019\n",
    "# Split the \"Electric\" column and check the resulting columns\n",
    "split_columns2019 = historical_data_clean2019[\"Electric\"].str.split(' | ', expand=True)\n",
    "print(split_columns2019.head())  # Check the number of columns created\n",
    "# If the split operation creates more than 3 columns, adjust the assignment accordingly\n",
    "if split_columns2019.shape[1] >= 3:\n",
    "    historical_data_clean2019[[\"Electric Stations\",\"unneeded\", \"Electric Charging Outlets\"]] = split_columns2019.iloc[:, :3]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns to assign to 'Electrical Stations' and 'Electrical Charging Outlets'.\")\n",
    "#2018\n",
    "# Split the \"Electric\" column and check the resulting columns\n",
    "split_columns2018 = historical_data_clean2018[\"Electric\"].str.split(' | ', expand=True)\n",
    "print(split_columns2018.head())  # Check the number of columns created\n",
    "# If the split operation creates more than 3 columns, adjust the assignment accordingly\n",
    "if split_columns2018.shape[1] >= 3:\n",
    "    historical_data_clean2018[[\"Electric Stations\",\"unneeded\", \"Electric Charging Outlets\"]] = split_columns2018.iloc[:, :3]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns to assign to 'Electrical Stations' and 'Electrical Charging Outlets'.\")\n",
    "#2017\n",
    "# Split the \"Electric\" column and check the resulting columns\n",
    "split_columns2017 = historical_data_clean2017[\"Electric\"].str.split(' | ', expand=True)\n",
    "print(split_columns2017.head())  # Check the number of columns created\n",
    "# If the split operation creates more than 3 columns, adjust the assignment accordingly\n",
    "if split_columns2017.shape[1] >= 3:\n",
    "    historical_data_clean2017[[\"Electric Stations\",\"unneeded\", \"Electric Charging Outlets\"]] = split_columns2017.iloc[:, :3]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns to assign to 'Electrical Stations' and 'Electrical Charging Outlets'.\")\n",
    "#2016\n",
    "# Split the \"Electric\" column and check the resulting columns\n",
    "split_columns2016 = historical_data_clean2016[\"Electric\"].str.split(' | ', expand=True)\n",
    "print(split_columns2016.head())  # Check the number of columns created\n",
    "# If the split operation creates more than 3 columns, adjust the assignment accordingly\n",
    "if split_columns2016.shape[1] >= 3:\n",
    "    historical_data_clean2016[[\"Electric Stations\",\"unneeded\", \"Electric Charging Outlets\"]] = split_columns2016.iloc[:, :3]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns to assign to 'Electrical Stations' and 'Electrical Charging Outlets'.\")\n",
    "#2015\n",
    "# Split the \"Electric\" column and check the resulting columns\n",
    "split_columns2015 = historical_data_clean2015[\"Electric\"].str.split(' | ', expand=True)\n",
    "print(split_columns2015.head())  # Check the number of columns created\n",
    "# If the split operation creates more than 3 columns, adjust the assignment accordingly\n",
    "if split_columns2015.shape[1] >= 3:\n",
    "    historical_data_clean2015[[\"Electric Stations\",\"unneeded\", \"Electric Charging Outlets\"]] = split_columns2015.iloc[:, :3]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns to assign to 'Electrical Stations' and 'Electrical Charging Outlets'.\")\n",
    "#2014\n",
    "# Split the \"Electric\" column and check the resulting columns\n",
    "split_columns2014 = historical_data_clean2014[\"Electric\"].str.split(' | ', expand=True)\n",
    "print(split_columns2014.head())  # Check the number of columns created\n",
    "# If the split operation creates more than 3 columns, adjust the assignment accordingly\n",
    "if split_columns2014.shape[1] >= 3:\n",
    "    historical_data_clean2014[[\"Electric Stations\",\"unneeded\", \"Electric Charging Outlets\"]] = split_columns2014.iloc[:, :3]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns to assign to 'Electrical Stations' and 'Electrical Charging Outlets'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12135f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2019\n",
    "# Split the \"Hydrogen\" column and check the resulting columns\n",
    "split_columns_hy2019 = historical_data_clean2019[\"Hydrogen\"].str.split(' | | ', expand=True)\n",
    "print(split_columns_hy2019.head())  # Check the number of columns created\n",
    "# If the split operation creates more than 5 columns, adjust the assignment accordingly\n",
    "if split_columns_hy2019.shape[1] >= 5:\n",
    "    historical_data_clean2019[[\"Hydrogen Retail\",\"unneeded2\",\"Hydrogen Non-Retail\",\"unneeded3\", \"Hydrogen Total\"]] = split_columns_hy2019.iloc[:, :5]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns.\")\n",
    "#2018\n",
    "# Split the \"Hydrogen\" column and check the resulting columns\n",
    "split_columns_hy2018 = historical_data_clean2018[\"Hydrogen\"].str.split(' | | ', expand=True)\n",
    "print(split_columns_hy2018.head())  # Check the number of columns created\n",
    "# If the split operation creates more than 5 columns, adjust the assignment accordingly\n",
    "if split_columns_hy2018.shape[1] >= 5:\n",
    "    historical_data_clean2018[[\"Hydrogen Retail\",\"unneeded2\",\"Hydrogen Non-Retail\",\"unneeded3\", \"Hydrogen Total\"]] = split_columns_hy2018.iloc[:, :5]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns.\")\n",
    "#2017\n",
    "# Split the \"Hydrogen\" column and check the resulting columns\n",
    "split_columns_hy2017 = historical_data_clean2017[\"Hydrogen\"].str.split(' | | ', expand=True)\n",
    "print(split_columns_hy2017.head())  # Check the number of columns created\n",
    "# If the split operation creates more than 5 columns, adjust the assignment accordingly\n",
    "if split_columns_hy2017.shape[1] >= 5:\n",
    "    historical_data_clean2017[[\"Hydrogen Retail\",\"unneeded2\",\"Hydrogen Non-Retail\",\"unneeded3\", \"Hydrogen Total\"]] = split_columns_hy2017.iloc[:, :5]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns.\")\n",
    "#2016\n",
    "# Split the \"Hydrogen\" column and check the resulting columns\n",
    "split_columns_hy2016 = historical_data_clean2016[\"Hydrogen\"].str.split(' | | ', expand=True)\n",
    "print(split_columns_hy2016.head())  # Check the number of columns created\n",
    "# If the split operation creates more than 5 columns, adjust the assignment accordingly\n",
    "if split_columns_hy2016.shape[1] >= 5:\n",
    "    historical_data_clean2016[[\"Hydrogen Retail\",\"unneeded2\",\"Hydrogen Non-Retail\",\"unneeded3\", \"Hydrogen Total\"]] = split_columns_hy2016.iloc[:, :5]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns.\")\n",
    "#2015\n",
    "# Split the \"Hydrogen\" column and check the resulting columns\n",
    "split_columns_hy2015 = historical_data_clean2015[\"Hydrogen\"].str.split(' | | ', expand=True)\n",
    "print(split_columns_hy2015.head())  # Check the number of columns created\n",
    "# If the split operation creates more than 5 columns, adjust the assignment accordingly\n",
    "if split_columns_hy2015.shape[1] >= 5:\n",
    "    historical_data_clean2015[[\"Hydrogen Retail\",\"unneeded2\",\"Hydrogen Non-Retail\",\"unneeded3\", \"Hydrogen Total\"]] = split_columns_hy2015.iloc[:, :5]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns.\")\n",
    "#2014\n",
    "# Split the \"Hydrogen\" column and check the resulting columns\n",
    "split_columns_hy2014 = historical_data_clean2014[\"Hydrogen\"].str.split(' | | ', expand=True)\n",
    "print(split_columns_hy2014.head())  # Check the number of columns created\n",
    "# If the split operation creates more than 5 columns, adjust the assignment accordingly\n",
    "if split_columns_hy2014.shape[1] >= 5:\n",
    "    historical_data_clean2014[[\"Hydrogen Retail\",\"unneeded2\",\"Hydrogen Non-Retail\",\"unneeded3\", \"Hydrogen Total\"]] = split_columns_hy2014.iloc[:, :5]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42e9c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2019\n",
    "# Split the \"Propane\" column and check the resulting columns\n",
    "split_columns_pr2019 = historical_data_clean2019[\"Propane\"].str.split(' | | ', expand=True)\n",
    "print(split_columns_pr2019.head())  # Check the number of columns created\n",
    "# If the split operation creates more than 5 columns, adjust the assignment accordingly\n",
    "if split_columns_pr2019.shape[1] >= 5:\n",
    "    historical_data_clean2019[[\"Propane Primary\",\"unneeded4\",\"Propane Secondary\",\"unneeded5\", \"Propane Total\"]] = split_columns_pr2019.iloc[:, :5]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns.\")\n",
    "#2018\n",
    "# Split the \"Propane\" column and check the resulting columns\n",
    "split_columns_pr2018 = historical_data_clean2018[\"Propane\"].str.split(' | | ', expand=True)\n",
    "print(split_columns_pr2018.head())  # Check the number of columns created\n",
    "# If the split operation creates more than 5 columns, adjust the assignment accordingly\n",
    "if split_columns_pr2018.shape[1] >= 5:\n",
    "    historical_data_clean2018[[\"Propane Primary\",\"unneeded4\",\"Propane Secondary\",\"unneeded5\", \"Propane Total\"]] = split_columns_pr2018.iloc[:, :5]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns.\")\n",
    "#2017\n",
    "# Split the \"Propane\" column and check the resulting columns\n",
    "split_columns_pr2017 = historical_data_clean2017[\"Propane\"].str.split(' | | ', expand=True)\n",
    "print(split_columns_pr2017.head())  # Check the number of columns created\n",
    "# If the split operation creates more than 5 columns, adjust the assignment accordingly\n",
    "if split_columns_pr2017.shape[1] >= 5:\n",
    "    historical_data_clean2017[[\"Propane Primary\",\"unneeded4\",\"Propane Secondary\",\"unneeded5\", \"Propane Total\"]] = split_columns_pr2017.iloc[:, :5]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns.\")\n",
    "#2016\n",
    "# Split the \"Propane\" column and check the resulting columns\n",
    "split_columns_pr2016 = historical_data_clean2016[\"Propane\"].str.split(' | | ', expand=True)\n",
    "print(split_columns_pr2016.head())  # Check the number of columns created\n",
    "# If the split operation creates more than 5 columns, adjust the assignment accordingly\n",
    "if split_columns_pr2016.shape[1] >= 5:\n",
    "    historical_data_clean2016[[\"Propane Primary\",\"unneeded4\",\"Propane Secondary\",\"unneeded5\", \"Propane Total\"]] = split_columns_pr2016.iloc[:, :5]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns.\")\n",
    "#2015\n",
    "# Split the \"Propane\" column and check the resulting columns\n",
    "split_columns_pr2015 = historical_data_clean2015[\"Propane\"].str.split(' | | ', expand=True)\n",
    "print(split_columns_pr2015.head())  # Check the number of columns created\n",
    "# If the split operation creates more than 5 columns, adjust the assignment accordingly\n",
    "if split_columns_pr2015.shape[1] >= 5:\n",
    "    historical_data_clean2015[[\"Propane Primary\",\"unneeded4\",\"Propane Secondary\",\"unneeded5\", \"Propane Total\"]] = split_columns_pr2015.iloc[:, :5]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns.\")\n",
    "#2014\n",
    "# Split the \"Propane\" column and check the resulting columns\n",
    "split_columns_pr2014 = historical_data_clean2014[\"Propane\"].str.split(' | | ', expand=True)\n",
    "print(split_columns_pr2014.head())  # Check the number of columns created\n",
    "# If the split operation creates more than 5 columns, adjust the assignment accordingly\n",
    "if split_columns_pr2014.shape[1] >= 5:\n",
    "    historical_data_clean2014[[\"Propane Primary\",\"unneeded4\",\"Propane Secondary\",\"unneeded5\", \"Propane Total\"]] = split_columns_pr2014.iloc[:, :5]\n",
    "else:\n",
    "    print(\"Split operation did not create enough columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394db17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2019\n",
    "# remove unneeded column\n",
    "historical2019 = historical_data_clean2019.drop(columns=[\"Electric\",\"Hydrogen\",\"Propane\",\"unneeded\",\"unneeded2\",\"unneeded3\",\"unneeded4\",\"unneeded5\"])\n",
    "historical2019.head()\n",
    "#2018\n",
    "# remove unneeded column\n",
    "historical2018 = historical_data_clean2018.drop(columns=[\"Electric\",\"Hydrogen\",\"Propane\",\"unneeded\",\"unneeded2\",\"unneeded3\",\"unneeded4\",\"unneeded5\"])\n",
    "historical2018.head()\n",
    "#2017\n",
    "# remove unneeded column\n",
    "historical2017 = historical_data_clean2017.drop(columns=[\"Electric\",\"Hydrogen\",\"Propane\",\"unneeded\",\"unneeded2\",\"unneeded3\",\"unneeded4\",\"unneeded5\"])\n",
    "historical2017.head()\n",
    "#2016\n",
    "# remove unneeded column\n",
    "historical2016 = historical_data_clean2016.drop(columns=[\"Electric\",\"Hydrogen\",\"Propane\",\"unneeded\",\"unneeded2\",\"unneeded3\",\"unneeded4\",\"unneeded5\"])\n",
    "historical2016.head()\n",
    "#2015\n",
    "# remove unneeded column\n",
    "historical2015 = historical_data_clean2015.drop(columns=[\"Electric\",\"Hydrogen\",\"Propane\",\"unneeded\",\"unneeded2\",\"unneeded3\",\"unneeded4\",\"unneeded5\"])\n",
    "historical2015.head()\n",
    "#2014\n",
    "# remove unneeded column\n",
    "historical2014 = historical_data_clean2014.drop(columns=[\"Electric\",\"Hydrogen\",\"Propane\",\"unneeded\",\"unneeded2\",\"unneeded3\",\"unneeded4\",\"unneeded5\"])\n",
    "historical2014.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad7765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2019\n",
    "#convert to float\n",
    "historical2019 = historical2019.applymap(lambda x: x.replace(',', '') if isinstance(x, str) else x)\n",
    "historical2019 = historical2019.astype(float)\n",
    "#2018\n",
    "#convert to float\n",
    "historical2018 = historical2018.applymap(lambda x: x.replace(',', '') if isinstance(x, str) else x)\n",
    "historical2018 = historical2018.astype(float)\n",
    "#2017\n",
    "#convert to float\n",
    "historical2017 = historical2017.applymap(lambda x: x.replace(',', '') if isinstance(x, str) else x)\n",
    "historical2017 = historical2017.astype(float)\n",
    "#2016\n",
    "#convert to float\n",
    "historical2016 = historical2016.applymap(lambda x: x.replace(',', '') if isinstance(x, str) else x)\n",
    "historical2016 = historical2016.astype(float)\n",
    "#2015\n",
    "#convert to float\n",
    "historical2015 = historical2015.applymap(lambda x: x.replace(',', '') if isinstance(x, str) else x)\n",
    "historical2015 = historical2015.astype(float)\n",
    "#2014\n",
    "#convert to float\n",
    "historical2014 = historical2014.applymap(lambda x: x.replace(',', '') if isinstance(x, str) else x)\n",
    "historical2014 = historical2014.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d5669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Electric Total column \n",
    "# Put columns in correct order\n",
    "#2019\n",
    "historical2019['Electric Total']= historical2019[['Electric Stations','Electric Charging Outlets']].sum(axis=1)\n",
    "historical2019['Year']='2019'\n",
    "historical_df_2019 = historical2019.reindex(columns=['Year','Biodiesel','CNG','E85','Electric Stations','Electric Charging Outlets',\n",
    "                                           'Electric Total','Hydrogen Retail','Hydrogen Non-Retail','Hydrogen Total',\n",
    "                                           'LNG','Propane Primary','Propane Secondary', 'Propane Total','Total'])\n",
    "#2018\n",
    "historical2018['Electric Total']= historical2018[['Electric Stations','Electric Charging Outlets']].sum(axis=1)\n",
    "historical2018['Year']='2018'\n",
    "historical_df_2018 = historical2018.reindex(columns=['Year','Biodiesel','CNG','E85','Electric Stations','Electric Charging Outlets',\n",
    "                                           'Electric Total','Hydrogen Retail','Hydrogen Non-Retail','Hydrogen Total',\n",
    "                                           'LNG','Propane Primary','Propane Secondary', 'Propane Total','Total'])\n",
    "#2017\n",
    "historical2017['Electric Total']= historical2017[['Electric Stations','Electric Charging Outlets']].sum(axis=1)\n",
    "historical2017['Year']='2017'\n",
    "historical_df_2017 = historical2017.reindex(columns=['Year','Biodiesel','CNG','E85','Electric Stations','Electric Charging Outlets',\n",
    "                                           'Electric Total','Hydrogen Retail','Hydrogen Non-Retail','Hydrogen Total',\n",
    "                                           'LNG','Propane Primary','Propane Secondary', 'Propane Total','Total'])\n",
    "#2016\n",
    "historical2016['Electric Total']= historical2016[['Electric Stations','Electric Charging Outlets']].sum(axis=1)\n",
    "historical2016['Year']='2016'\n",
    "historical_df_2016 = historical2016.reindex(columns=['Year','Biodiesel','CNG','E85','Electric Stations','Electric Charging Outlets',\n",
    "                                           'Electric Total','Hydrogen Retail','Hydrogen Non-Retail','Hydrogen Total',\n",
    "                                           'LNG','Propane Primary','Propane Secondary', 'Propane Total','Total'])\n",
    "#2015\n",
    "historical2015['Electric Total']= historical2015[['Electric Stations','Electric Charging Outlets']].sum(axis=1)\n",
    "historical2015['Year']='2015'\n",
    "historical_df_2015 = historical2015.reindex(columns=['Year','Biodiesel','CNG','E85','Electric Stations','Electric Charging Outlets',\n",
    "                                           'Electric Total','Hydrogen Retail','Hydrogen Non-Retail','Hydrogen Total',\n",
    "                                           'LNG','Propane Primary','Propane Secondary', 'Propane Total','Total'])\n",
    "#2014\n",
    "historical2014['Electric Total']= historical2014[['Electric Stations','Electric Charging Outlets']].sum(axis=1)\n",
    "historical2014['Year']='2014'\n",
    "historical_df_2014 = historical2014.reindex(columns=['Year','Biodiesel','CNG','E85','Electric Stations','Electric Charging Outlets',\n",
    "                                           'Electric Total','Hydrogen Retail','Hydrogen Non-Retail','Hydrogen Total',\n",
    "                                           'LNG','Propane Primary','Propane Secondary', 'Propane Total','Total'])\n",
    "#display dataframe\n",
    "historical_df_2019\n",
    "#historical_df_2018\n",
    "#historical_df_2017\n",
    "#historical_df_2016\n",
    "#historical_df_2015\n",
    "#historical_df_2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61f63f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_df_2019.to_csv('historical_df_2019.csv')\n",
    "historical_df_2018.to_csv('historical_df_2018.csv')\n",
    "historical_df_2017.to_csv('historical_df_2017.csv')\n",
    "historical_df_2016.to_csv('historical_df_2016.csv')\n",
    "historical_df_2016.to_csv('historical_df_2015.csv')\n",
    "historical_df_2014.to_csv('historical_df_2014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d557f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = historical_df_2023,historical_df_2022,historical_df_2021,historical_df_2020,historical_df_2019,historical_df_2018,historical_df_2017,historical_df_2016,historical_df_2015,historical_df_2014  \n",
    "all_historical = pd.concat(frames)\n",
    "\n",
    "all_historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4e232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_historical.to_csv('all_historical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebf7784",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
